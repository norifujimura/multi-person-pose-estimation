{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0648be23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import urllib.request\n",
    "\n",
    "def detect(interpreter, input_tensor):\n",
    "  \"\"\"Runs detection on an input image.\n",
    "\n",
    "  Args:\n",
    "    interpreter: tf.lite.Interpreter\n",
    "    input_tensor: A [1, input_height, input_width, 3] Tensor of type tf.float32.\n",
    "      input_size is specified when converting the model to TFLite.\n",
    "\n",
    "  Returns:\n",
    "    A tensor of shape [1, 6, 56].\n",
    "  \"\"\"\n",
    "\n",
    "  input_details = interpreter.get_input_details()\n",
    "  output_details = interpreter.get_output_details()\n",
    "\n",
    "  is_dynamic_shape_model = input_details[0]['shape_signature'][2] == -1\n",
    "  if is_dynamic_shape_model:\n",
    "    input_tensor_index = input_details[0]['index']\n",
    "    input_shape = input_tensor.shape\n",
    "    interpreter.resize_tensor_input(\n",
    "        input_tensor_index, input_shape, strict=True)\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  interpreter.set_tensor(input_details[0]['index'], input_tensor.numpy())\n",
    "\n",
    "  interpreter.invoke()\n",
    "\n",
    "  keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])\n",
    "  return keypoints_with_scores\n",
    "\n",
    "def keep_aspect_ratio_resizer(image, target_size):\n",
    "  \"\"\"Resizes the image.\n",
    "\n",
    "  The function resizes the image such that its longer side matches the required\n",
    "  target_size while keeping the image aspect ratio. Note that the resizes image\n",
    "  is padded such that both height and width are a multiple of 32, which is\n",
    "  required by the model.\n",
    "  \"\"\"\n",
    "  _, height, width, _ = image.shape\n",
    "  if height > width:\n",
    "    scale = float(target_size / height)\n",
    "    target_height = target_size\n",
    "    scaled_width = math.ceil(width * scale)\n",
    "    image = tf.image.resize(image, [target_height, scaled_width])\n",
    "    target_width = int(math.ceil(scaled_width / 32) * 32)\n",
    "  else:\n",
    "    scale = float(target_size / width)\n",
    "    target_width = target_size\n",
    "    scaled_height = math.ceil(height * scale)\n",
    "    image = tf.image.resize(image, [scaled_height, target_width])\n",
    "    target_height = int(math.ceil(scaled_height / 32) * 32)\n",
    "  image = tf.image.pad_to_bounding_box(image, 0, 0, target_height, target_width)\n",
    "  return (image,  (target_height, target_width))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "142eef12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to resize dimension 3 of tensor 0 with value 3 to 4. ResizeInputTensorStrict only allows mutating unknown dimensions identified by -1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m interpreter \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlite\u001b[38;5;241m.\u001b[39mInterpreter(model_path\u001b[38;5;241m=\u001b[39mmodel_path)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Output: [1, 6, 56] tensor that contains keypoints/bbox/scores.\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m keypoints_with_scores \u001b[38;5;241m=\u001b[39m \u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterpreter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 26\u001b[0m, in \u001b[0;36mdetect\u001b[0;34m(interpreter, input_tensor)\u001b[0m\n\u001b[1;32m     24\u001b[0m   input_tensor_index \u001b[38;5;241m=\u001b[39m input_details[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     25\u001b[0m   input_shape \u001b[38;5;241m=\u001b[39m input_tensor\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m---> 26\u001b[0m   \u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize_tensor_input\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_tensor_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m interpreter\u001b[38;5;241m.\u001b[39mallocate_tensors()\n\u001b[1;32m     30\u001b[0m interpreter\u001b[38;5;241m.\u001b[39mset_tensor(input_details[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m], input_tensor\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/lib/python3.9/site-packages/tensorflow/lite/python/interpreter.py:749\u001b[0m, in \u001b[0;36mInterpreter.resize_tensor_input\u001b[0;34m(self, input_index, tensor_size, strict)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;66;03m# `ResizeInputTensor` now only accepts int32 numpy array as `tensor_size\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# parameter.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m tensor_size \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(tensor_size, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)\n\u001b[0;32m--> 749\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResizeInputTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to resize dimension 3 of tensor 0 with value 3 to 4. ResizeInputTensorStrict only allows mutating unknown dimensions identified by -1."
     ]
    }
   ],
   "source": [
    "# Load the input image.\n",
    "input_size = 256\n",
    "image_path = 'tennis.jpg'\n",
    "image = tf.io.read_file(image_path)\n",
    "image = tf.compat.v1.image.decode_jpeg(image)\n",
    "image = tf.expand_dims(image, axis=0)\n",
    "\n",
    "# Resize and pad the image to keep the aspect ratio and fit the expected size.\n",
    "resized_image, image_shape = keep_aspect_ratio_resizer(image, input_size)\n",
    "image_tensor = tf.cast(resized_image, dtype=tf.uint8)\n",
    "\n",
    "#model_path = '/kaggle/input/movenet/tflite/multipose-lightning-tflite-float16/1/1.tflite'\n",
    "model_path = '1.tflite'\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "\n",
    "# Output: [1, 6, 56] tensor that contains keypoints/bbox/scores.\n",
    "keypoints_with_scores = detect(\n",
    "    interpreter, tf.cast(image_tensor, dtype=tf.uint8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562f0082",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
