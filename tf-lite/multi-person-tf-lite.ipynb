{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e9c41c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import urllib.request\n",
    "\n",
    "def detect(interpreter, input_tensor):\n",
    "  \"\"\"Runs detection on an input image.\n",
    "\n",
    "  Args:\n",
    "    interpreter: tf.lite.Interpreter\n",
    "    input_tensor: A [1, input_height, input_width, 3] Tensor of type tf.float32.\n",
    "      input_size is specified when converting the model to TFLite.\n",
    "\n",
    "  Returns:\n",
    "    A tensor of shape [1, 6, 56].\n",
    "  \"\"\"\n",
    "\n",
    "  input_details = interpreter.get_input_details()\n",
    "  output_details = interpreter.get_output_details()\n",
    "\n",
    "  is_dynamic_shape_model = input_details[0]['shape_signature'][2] == -1\n",
    "  if is_dynamic_shape_model:\n",
    "    input_tensor_index = input_details[0]['index']\n",
    "    input_shape = input_tensor.shape\n",
    "    interpreter.resize_tensor_input(\n",
    "        input_tensor_index, input_shape, strict=True)\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  interpreter.set_tensor(input_details[0]['index'], input_tensor.numpy())\n",
    "\n",
    "  interpreter.invoke()\n",
    "\n",
    "  keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])\n",
    "  return keypoints_with_scores\n",
    "\n",
    "def keep_aspect_ratio_resizer(image, target_size):\n",
    "  \"\"\"Resizes the image.\n",
    "\n",
    "  The function resizes the image such that its longer side matches the required\n",
    "  target_size while keeping the image aspect ratio. Note that the resizes image\n",
    "  is padded such that both height and width are a multiple of 32, which is\n",
    "  required by the model.\n",
    "  \"\"\"\n",
    "  _, height, width, _ = image.shape\n",
    "  if height > width:\n",
    "    scale = float(target_size / height)\n",
    "    target_height = target_size\n",
    "    scaled_width = math.ceil(width * scale)\n",
    "    image = tf.image.resize(image, [target_height, scaled_width])\n",
    "    target_width = int(math.ceil(scaled_width / 32) * 32)\n",
    "  else:\n",
    "    scale = float(target_size / width)\n",
    "    target_width = target_size\n",
    "    scaled_height = math.ceil(height * scale)\n",
    "    image = tf.image.resize(image, [scaled_height, target_width])\n",
    "    target_height = int(math.ceil(scaled_height / 32) * 32)\n",
    "  image = tf.image.pad_to_bounding_box(image, 0, 0, target_height, target_width)\n",
    "  return (image,  (target_height, target_width))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce11c25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "WARNING: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors (tensor#327 is a dynamic-sized tensor).\n"
     ]
    }
   ],
   "source": [
    "# Load the input image.\n",
    "input_size = 256\n",
    "image_path = 'tennis.jpg'\n",
    "image = tf.io.read_file(image_path)\n",
    "image = tf.compat.v1.image.decode_jpeg(image)\n",
    "image = tf.expand_dims(image, axis=0)\n",
    "\n",
    "# Resize and pad the image to keep the aspect ratio and fit the expected size.\n",
    "resized_image, image_shape = keep_aspect_ratio_resizer(image, input_size)\n",
    "image_tensor = tf.cast(resized_image, dtype=tf.uint8)\n",
    "\n",
    "#model_path = '/kaggle/input/movenet/tflite/multipose-lightning-tflite-float16/1/1.tflite'\n",
    "model_path = '1.tflite'\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "\n",
    "# Output: [1, 6, 56] tensor that contains keypoints/bbox/scores.\n",
    "keypoints_with_scores = detect(\n",
    "    interpreter, tf.cast(image_tensor, dtype=tf.uint8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c67e17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
